services:
  dev:
    # image: huggingface/transformers-pytorch-gpu:latest
    image: dl-workshop-dev
    # TODO: uncomment for ramdrive
    # tmpfs:
    #   - /ramdrive:size=100G
    # container_name: dl-workshop-dev
    # TODO: uncomment for GPU
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
    mem_limit: 128G # TODO
    shm_size: 128G
    volumes:
      - ../:/repo
      - /mnt/workshop:/host
